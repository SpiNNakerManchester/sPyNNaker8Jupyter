{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the NeuroRobotics Platform with SpiNNaker\n",
    "This will guide you in using the HBP NRP through the SpiNNaker Jupyter notebooks.  An example of the execution of a model that has been set up to run with SpiNNaker will be given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the NRP from Jupyter\n",
    "Once you are logged in to Jupyter, Start a terminal as shown in the diagram below.\n",
    "<img src=\"JupyterTerminal.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the terminal has loaded, you can start the NRP by executing the commands:\n",
    "<pre>\n",
    "   cle-nginx\n",
    "   cle-start\n",
    "</pre>\n",
    "<img src=\"JupyterStartNRP.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One the NRP has started, you can now access your own NRP on a URL like the following, replacing ```<username>``` with your username:\n",
    "\n",
    "    https://spinn-20.cs.man.ac.uk/user/<username>/proxy/9000/#/esv-private\n",
    "\n",
    "This will result in a login screen like the following:\n",
    "<img src=\"NRPLogin.png\">\n",
    "\n",
    "Use the username ```nrpuser``` and the password ```password``` to log in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the NRP to run an Experiment on SpiNNaker\n",
    "When you are logged in, you will see a \"Templates\" screen.  Look for an experiment called \"Holodeck Husky Braitenberg Example on SpiNNaker\".  Select this, and select the \"Clone\" button.\n",
    "<img src=\"NRPTemplates.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now see the experiment in the \"My experiments\" tab.  Select the cloned example, and click on \"Launch\" to start the environment.\n",
    "<img src=\"NRPMyExperiments.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now see a loading screen:\n",
    "<img src=\"NRPLoading.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading is complete, you will see the NRP environment.  Click on the Play button to start the execution.\n",
    "<img src=\"NRPPlay.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution on SpiNNaker will now happen.  This will take a little while to happen; if you want, you can return to your Terminal tab to see the execution process.\n",
    "<img src=\"NRPPlaying.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the simulation starts, the Robot should start spinning on the spot.  You can now interact with the simulation.  The robot is looking for a red screen, so you can right-click on one of the screens to turn it red.\n",
    "<img src=\"NRPScreens.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the robot moves toward the screen, you can turn it blue again.  If you then turn the opposite screen red, the robot will turn until it sees that and move towards it.\n",
    "\n",
    "Once you have finished the simulation, select the Exit button to shut down the simulation.\n",
    "<img src=\"NRPStop.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then stop the NRP itself from the Terminal again, by typing the CTRL-C keys and then typing ```cle-kill```.\n",
    "<img src=\"JupyterNRPKill.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NRP Files\n",
    "\n",
    "Inside the ```nrpStorage``` folder there should now be a sub-folder called ```braitenberg_husky_holodeck_spinnaker_0```.  This contains all the experiment files.  In particular there are the following files:\n",
    "\n",
    " - braitenberg_spinnaker.py - This is the brain of the Robot as a PyNN script that will run on SpiNNaker.\n",
    " - eye_sensor_transmit.py - This is a Transfer Function that reads the eye sensors of the robot and then sends messages to SpiNNaker as the input to the brain.\n",
    " - linear_twist.py - This is a Transfer Function that reads the membrane voltage of neurons running on SpiNNaker and controls the speed of the robot motors.\n",
    " - bibi_configuration.bibi - This is the configuration file that joins together the parts of the experiment, as well as indicating that it should run on SpiNNaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Brain PyNN Description\n",
    "The Brain description is a neural network that runs on SpiNNaker.  Note that this only contains the neurons of the brain, not the input and output devices.  These devices are added by the Transfer Functions (see later).\n",
    "\n",
    "The Brain network used by the example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hbp_nrp_cle.brainsim import simulator as sim\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def create_brain():\n",
    "    \"\"\"\n",
    "    Initializes PyNN with the neuronal network that has to be simulated\n",
    "    \"\"\"\n",
    "    SENSORPARAMS = {'v_rest': -60.5,\n",
    "                    'cm': 0.025,\n",
    "                    'tau_m': 10.,\n",
    "                    'tau_refrac': 10.0,\n",
    "                    'tau_syn_E': 2.5,\n",
    "                    'tau_syn_I': 2.5,\n",
    "                    'e_rev_E': 0.0,\n",
    "                    'e_rev_I': -75.0,\n",
    "                    'v_thresh': -60.0,\n",
    "                    'v_reset': -60.5}\n",
    "\n",
    "    GO_ON_PARAMS = {'v_rest': -60.5,\n",
    "                    'cm': 0.025,\n",
    "                    'tau_m': 10.0,\n",
    "                    'e_rev_E': 0.0,\n",
    "                    'e_rev_I': -75.0,\n",
    "                    'v_reset': -61.6,\n",
    "                    'v_thresh': -60.51,\n",
    "                    'tau_refrac': 10.0,\n",
    "                    'tau_syn_E': 2.5,\n",
    "                    'tau_syn_I': 2.5}\n",
    "\n",
    "    # POPULATION_PARAMS = SENSORPARAMS * 5 + GO_ON_PARAMS + SENSORPARAMS * 2\n",
    "    red_left_eye = sim.Population(2, sim.IF_cond_exp(**SENSORPARAMS), label=\"red_left_eye\")\n",
    "    red_right_eye = sim.Population(2, sim.IF_cond_exp(**SENSORPARAMS), label=\"red_right_eye\")\n",
    "    green_blue_eye = sim.Population(1, sim.IF_cond_exp(**SENSORPARAMS), label=\"green_blue_eye\")\n",
    "    go_on = sim.Population(1, sim.IF_cond_exp(**GO_ON_PARAMS), label=\"go_on\")\n",
    "    left_wheel_motor = sim.Population(1, sim.IF_cond_exp(**SENSORPARAMS), label=\"left_wheel_motor\")\n",
    "    right_wheel_motor = sim.Population(1, sim.IF_cond_exp(**SENSORPARAMS), label=\"right_wheel_motor\")\n",
    "\n",
    "    # population = sim.Population(8, sim.IF_cond_exp())\n",
    "    # population[0:5].set(**SENSORPARAMS) # 0, 2 = red_left_eye, 1, 3 = red_right_eye, 4 = green_blue_eye\n",
    "    # population[5:6].set(**GO_ON_PARAMS) # 5 = go_on?\n",
    "    # population[6:8].set(**SENSORPARAMS) # 6 = left_wheel_motor, 7=right_wheel_motor\n",
    "\n",
    "    # Shared Synapse Parameters\n",
    "    # syn_params = {'U': 1.0, 'tau_rec': 1.0, 'tau_facil': 1.0}\n",
    "\n",
    "    # Synaptic weights\n",
    "    WEIGHT_RED_TO_ACTOR = 1.5e-4\n",
    "    WEIGHT_RED_TO_GO_ON = 1.2e-3  # or -1.2e-3?\n",
    "    WEIGHT_GREEN_BLUE_TO_ACTOR = 1.05e-4\n",
    "    WEIGHT_GO_ON_TO_RIGHT_ACTOR = 1.4e-4\n",
    "    DELAY = 0.1\n",
    "\n",
    "    # Connect neurons\n",
    "\n",
    "    SYN = sim.StaticSynapse(weight=abs(WEIGHT_RED_TO_ACTOR), delay=DELAY)\n",
    "    sim.Projection(red_left_eye, # red_left_eye[1]\n",
    "                   right_wheel_motor, # right_wheel_motor\n",
    "                   connector=sim.FromListConnector([(1, 0)]),\n",
    "                   synapse_type=SYN,\n",
    "                   receptor_type='excitatory')\n",
    "    sim.Projection(red_right_eye, # red_right_eye[1]\n",
    "                   left_wheel_motor, # left_wheel_motor\n",
    "                   connector=sim.FromListConnector([(1, 0)]),\n",
    "                   synapse_type=SYN,\n",
    "                   receptor_type='excitatory')\n",
    "\n",
    "    SYN = sim.StaticSynapse(weight=abs(WEIGHT_RED_TO_GO_ON), delay=DELAY)\n",
    "    sim.Projection(red_left_eye, # red_left_eye\n",
    "                   green_blue_eye, # green_blue_eye\n",
    "                   connector=sim.AllToAllConnector(),\n",
    "                   synapse_type=SYN,\n",
    "                   receptor_type='inhibitory')\n",
    "    sim.Projection(red_left_eye, # red_left_eye\n",
    "                   go_on, # go_on\n",
    "                   connector=sim.AllToAllConnector(),\n",
    "                   synapse_type=SYN,\n",
    "                   receptor_type='inhibitory')\n",
    "\n",
    "    SYN = sim.StaticSynapse(weight=abs(WEIGHT_GREEN_BLUE_TO_ACTOR), delay=DELAY)\n",
    "    sim.Projection(green_blue_eye, # green_blue_eye\n",
    "                   right_wheel_motor, # right_wheel_motor\n",
    "                   connector=sim.AllToAllConnector(),\n",
    "                   synapse_type=SYN,\n",
    "                   receptor_type='excitatory')\n",
    "\n",
    "    SYN = sim.StaticSynapse(weight=abs(WEIGHT_GO_ON_TO_RIGHT_ACTOR), delay=DELAY)\n",
    "    sim.Projection(go_on, # go_on\n",
    "                   right_wheel_motor, # right_wheel_motor\n",
    "                   connector=sim.AllToAllConnector(),\n",
    "                   synapse_type=SYN,\n",
    "                   receptor_type='excitatory')\n",
    "\n",
    "    # sim.initialize(population, v=population.get('v_rest'))\n",
    "\n",
    "    # logger.debug(\"Circuit description: \" + str(population.describe()))\n",
    "\n",
    "    return {\"red_left_eye\": red_left_eye, \"red_right_eye\": red_right_eye,\n",
    "            \"green_blue_eye\": green_blue_eye, \"go_on\": go_on,\n",
    "            \"left_wheel_motor\": left_wheel_motor, \"right_wheel_motor\": right_wheel_motor}\n",
    "\n",
    "\n",
    "circuit = create_brain()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates several ```Population``` objects and connects them together using ```Projection``` as normal in a PyNN network.  The only difference is that at the end of the script, a dictionary is created called ```circuit``` which contains the Populations that will be used in the NRP experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Functions\n",
    "Once the Brain has been defined, Transfer Functions can be written which will communicate between the Brain and the Robot.  The Transfer Function that sends the input into the network from the eyes of the Robot is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nrp.MapRobotSubscriber(\"camera\", Topic('/husky/husky/camera', sensor_msgs.msg.Image))\n",
    "@nrp.MapSpikeSource(\"red_left_eye\", nrp.brain.red_left_eye, nrp.poisson)\n",
    "@nrp.MapSpikeSource(\"red_right_eye\", nrp.brain.red_right_eye, nrp.poisson)\n",
    "@nrp.MapSpikeSource(\"green_blue_eye\", nrp.brain.green_blue_eye, nrp.poisson)\n",
    "@nrp.Robot2Neuron()\n",
    "def eye_sensor_transmit(t, camera, red_left_eye, red_right_eye, green_blue_eye):\n",
    "    image_results = hbp_nrp_cle.tf_framework.tf_lib.detect_red(image=camera.value)\n",
    "    red_left_eye.rate = 2000.0 * image_results.left\n",
    "    red_right_eye.rate = 2000.0 * image_results.right\n",
    "    green_blue_eye.rate = 75.0 * image_results.go_on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first sets up a link from the robot camera to the function argument \"camera\".  This uses ROS to communicate with the camera.\n",
    "\n",
    "Next, three of the ```Population``` objects are connected to externally controlled Poisson sources.  Internally, this creates a Poisson source for each of the Populations, and then creates a Projection from each to the Population respectively.  The Poisson sources are each provided as arguments to the function.\n",
    "\n",
    "Finally, the function is marked as ```Robot2Neuron``` indicating it is inputting into the Brain.\n",
    "\n",
    "The function itself takes the camera image and performs some processing on it to extract which parts are red and which are green and blue.  The function takes these results and updates the Poisson rates of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Transfer Function that controls the motors is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nrp.MapSpikeSink(\"left_wheel_neuron\", nrp.brain.left_wheel_motor, nrp.leaky_integrator_exp, weight=0.1)\n",
    "@nrp.MapSpikeSink(\"right_wheel_neuron\", nrp.brain.right_wheel_motor, nrp.leaky_integrator_exp, weight=0.1)\n",
    "@nrp.Neuron2Robot(Topic('/husky/husky/cmd_vel', geometry_msgs.msg.Twist))\n",
    "def linear_twist(t, left_wheel_neuron, right_wheel_neuron):\n",
    "    return geometry_msgs.msg.Twist(linear=geometry_msgs.msg.Vector3(x=20.0 * min(left_wheel_neuron.voltage, right_wheel_neuron.voltage), y=0.0, z=0.0), angular=geometry_msgs.msg.Vector3(x=0.0, y=0.0, z=100.0 * (right_wheel_neuron.voltage - left_wheel_neuron.voltage)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first sets up Populations from which the Membrane voltage can be read.  Like the Poisson sources in the previous example, these are in addition to the network described in the brain.  These are connected to the specified brain Populations using a Projection; in this case the weight is explicitly specified.  These are then provided to the function as the arguments specified.\n",
    "\n",
    "The next line tells the platform that the robot will be sent a ```Twist``` object through the ROS topic ```/husky/husky/cmd_vel```.  The function then takes the voltages of the neurons and returns this object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibi File\n",
    "The final part of the experiment is the bibi file.  This connects the parts of the experiment together.  Below is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<ns1:bibi \n",
    "  xmlns:ns1=\"http://schemas.humanbrainproject.eu/SP10/2014/BIBI\" \n",
    "  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n",
    "  <ns1:brainModel>\n",
    "    <ns1:file>braitenberg_spinnaker.py</ns1:file>\n",
    "    <ns1:populations population=\"red_left_eye\" count=\"2\" xsi:type=\"ns1:Population\" />\n",
    "    <ns1:populations population=\"red_right_eye\" count=\"2\" xsi:type=\"ns1:Population\" />\n",
    "    <ns1:populations population=\"green_blue_eye\" count=\"1\" xsi:type=\"ns1:Population\" />\n",
    "    <ns1:populations population=\"go_on\" count=\"1\" xsi:type=\"ns1:Population\" />\n",
    "    <ns1:populations population=\"left_wheel_motor\" count=\"1\" xsi:type=\"ns1:Population\" />\n",
    "    <ns1:populations population=\"right_wheel_motor\" count=\"1\" xsi:type=\"ns1:Population\" />\n",
    "  </ns1:brainModel>\n",
    "  <ns1:bodyModel robotId=\"husky\">husky_model/model.sdf</ns1:bodyModel>\n",
    "  <ns1:mode>SynchronousSpinnakerSimulation</ns1:mode>\n",
    "  <ns1:transferFunction src=\"csv_spike_monitor.py\" xsi:type=\"ns1:PythonTransferFunction\" />\n",
    "  <ns1:transferFunction src=\"csv_joint_state_monitor.py\" xsi:type=\"ns1:PythonTransferFunction\" />\n",
    "  <ns1:transferFunction src=\"csv_robot_position.py\" xsi:type=\"ns1:PythonTransferFunction\" />\n",
    "  <ns1:transferFunction src=\"all_neurons_spike_monitor.py\" xsi:type=\"ns1:PythonTransferFunction\" />\n",
    "  <ns1:transferFunction src=\"linear_twist.py\" xsi:type=\"ns1:PythonTransferFunction\" />\n",
    "  <ns1:transferFunction src=\"eye_sensor_transmit.py\" xsi:type=\"ns1:PythonTransferFunction\" />\n",
    "</ns1:bibi>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the Populations of the Brain model are specified.  The body of the robot is then linked.  Following this, the system is told that the network is to be simulated using SpiNNaker with the mode ```SynchronousSpinnakerSimulation```.  The transfer functions are then listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sPyNNaker",
   "language": "python",
   "name": "spynnaker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
